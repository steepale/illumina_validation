#===============================================================================
#
#         FILE: home/proj/MDW_genomics/steepale/illumina_validation/nonsynonymous_somatic_snv_indel_validation_main_documentation.txt
#
#        USAGE: for documentation purposes, scripts inside
#
#  DESCRIPTION:  This script serves as a step by step documentation script and development script for performing mutation validation
#                
# REQUIREMENTS:  bedtools v2.25.0, samtools 1.3-20-gd49c73b (Using htslib 1.3-29-g091c89c), bcftools 1.3-27-gf31e888
#        NOTES:  ---
#       AUTHOR:  Alec Steep, steepale@msu.edu
#  AFFILIATION:  Michigan State University (MSU), East Lansing, MI, United States
#				         USDA ARS Avian Disease and Oncology Lab (ADOL), East Lansing, MI, United States
#				         Technical University of Munich (TUM), Weihenstephan, Germany
#      VERSION:  1.0
#      CREATED:  2017.03.17
#     REVISION:  
#===============================================================================

# Permanent PROJECT DIRECTORY (TUM Cluster)
cd /home/proj/MDW_genomics/steepale/illumina_validation

# We aim to validate a minimum of 125 50bp sequences with somatic snvs and indels. We will use a targeted
# illumina targeted sequence approach (short reads and high coverage). Thus, in order to design this targeted
# sequencing array, we must choose 125 50bp sequences to undergoe validation. We have a list of over 300 
# high confidence somatic snv and indel candidates, and thus we will prioritize these samples to 125 targets.
# Furthermore, we will collect the 100 bp consensus sequences flanking both sides of each variant.

# In order to calculate the consensus sequences, we will create a consesnus sequence based on all of our
# germline and tumor samples of F1 6x7 birds and line 6 and line 7 germline birds, all of which mapped to
# Galgal5.

# In order to prioritize our 125 50bp regions we will prioritize our filtering in this order:
# 2 or more variants that fit in a 50bp window across 1 or more samples
# Any non-synonymous varaint found in a gene, which is mutated in more than 1 sample
# Any varaint that is found in COSMIC's cancer gene consensus (annotation suggestive of high impact mutated gene)
# Consensus of variant callers greater than 1
# Variant allele count greater than 1
# Variant allele frequency
# Custom overview and editing of candidate list 

### Note: I had to write this script without interent on a plane to China. Not an elegant script

# Software references:
# Variant calling: Samtools and bcftools
# http://www.htslib.org/workflow/
# Flanking sequence calling: Pyfaidx which relied on pPyVCF
# https://www.biostars.org/p/183260/
# https://github.com/jamescasbon/PyVCF/


# Apply the prioritization filters to the somatic snv and indel candidates

python ./scripts/prioritize_somatic_snv_indel_candidates.py \
./data/somatic_snvs_and_indels_final.txt \
./data/somatic_snvs_and_indels_final_priority.int

# ./scripts/prioritize_somatic_snv_indel_candidates.py
#######################################################
import os
import sys
import re

# infile (open independently)
infile = sys.argv[1]

# outfile (open once and close once)
outfile = open(sys.argv[2], 'w')

# reference files
orthologue_file = "/home/users/a.steep/databases/ensembl/chicken_human_orthologues_full_annotation.txt"
cosmic_cgc_file = "/home/users/a.steep/databases/cosmic/cosmic_CGC_gene_list_2017_01_03.tsv"

# Create a dictionary of mutated genes to tally distinct sample counts
samples_by_gene = {}
for inline in open(infile):
	if inline[0] != '#':
		inline = inline.rstrip()
		incol = inline.split('\t')
		ingeneid = incol[7]
		insample = incol[9]
		insample_list = insample.split('|')
		if ingeneid not in samples_by_gene.keys():
			samples_by_gene[ingeneid] = set()
			samples_by_gene[ingeneid] |= set(insample_list)
		if ingeneid in samples_by_gene.keys():
			samples_by_gene[ingeneid] |= set(insample_list)

# Create a series of dictionaries of high confidence orthologues:
# Create a dictionary of high confidence orthologues of chicken ensembl gene id 2 human ensembl gene id
chicken2human_ortho_ensembl_gene_id = {}
# Create a dictionary of high confidence orthologues of chicken ensembl gene id 2 human ensembl gene name
chicken_ensembl_gene_id2human_ensembl_gene_name_ortho = {}
for o_line in open(orthologue_file):
	if o_line[0] != '#':
		o_line = o_line.rstrip()
		o_col = o_line.split('\t')
		c_e_gene_id = o_col[0]
		c_e_gene_name = o_col[1]
		c_e_gene_desc = o_col[2]
		h_e_gene_id = o_col[3]
		h_e_gene_name = o_col[4]
		homology = o_col[5]
		id_gene_h2c = o_col[6]
		id_gene_c2h = o_col[7]
		goc_score = o_col[8]
		wga_cov = o_col[9]
		ortho_score = o_col[10]
		# Fill dictionary of high confidence orthologues of chicken ensembl gene id 2 human ensembl gene id
		if c_e_gene_id not in chicken2human_ortho_ensembl_gene_id.keys() and ortho_score == '1':
			chicken2human_ortho_ensembl_gene_id[c_e_gene_id] = set()
			chicken2human_ortho_ensembl_gene_id[c_e_gene_id].add(h_e_gene_id)
		if c_e_gene_id in chicken2human_ortho_ensembl_gene_id.keys() and ortho_score == '1':
			chicken2human_ortho_ensembl_gene_id[c_e_gene_id].add(h_e_gene_id)
		# Fill dictionary of high confidence orthologues of chicken ensembl gene id 2 human ensembl gene name
		if c_e_gene_id not in chicken_ensembl_gene_id2human_ensembl_gene_name_ortho.keys() and ortho_score == '1':
			chicken_ensembl_gene_id2human_ensembl_gene_name_ortho[c_e_gene_id] = set()
			chicken_ensembl_gene_id2human_ensembl_gene_name_ortho[c_e_gene_id].add(h_e_gene_name)
		if c_e_gene_id in chicken_ensembl_gene_id2human_ensembl_gene_name_ortho.keys() and ortho_score == '1':
			chicken_ensembl_gene_id2human_ensembl_gene_name_ortho[c_e_gene_id].add(h_e_gene_name)


# Create a set of mutated genes in cancer gene consensus
cgc_gene_set = set()
for cgc_line in open(cosmic_cgc_file):
	cgc_line = cgc_line.rstrip()
	cgc_col = cgc_line.split('\t')
	cgc_gene = cgc_col[0]
	cgc_gene_set.add(cgc_gene)

# Create a set of final variants for output that pass filters
final_var_set = set()

# Write a header for the outfile
outfile.write('#CHROM'+'\t'+'POS'+'\t'+'REF'+'\t'+'ALT'+'\t'+'MUT'+'\t'+'IMPACT'+'\t'+'SYMBOL'+'\t'+'GENE_ID'+'\t'+'ORTHOLOGUE'+'\t'+'TSN_VAR'+'\t'+'TSN_GENE'+'\t'+'SAMPLE'+'\t'+'VAC'+'\t'+'VAF'+'\t'+'NUM_TOOLS'+'\t'+'CGC_STATUS'+'\t'+'FILTER'+'\n')

# Iterate through the infile and collect additional information for each filter
for inline in open(infile):
	if inline[0] != '#':
		inline = inline.rstrip()
		incol = inline.split('\t')
		inchr = incol[0]
		inpos = incol[1]
		inref = incol[2]
		inalt = incol[3]
		var_id = inchr+inpos+inref+inalt
		inmut = incol[4]
		inimpact = incol[5]
		insymbol = incol[6]
		ingeneid = incol[7]
		intsn_by_var = incol[8]
		intsn_by_gene = str(len(samples_by_gene[ingeneid]))
		insample = incol[9].replace('|', ';')
		invac = incol[10].replace('|', ';')
		invaf = incol[11].replace('|', ';')
		# Annotate validation site ID
		# Annotate gene if it has a high confidence orthologue
		if ingeneid in chicken_ensembl_gene_id2human_ensembl_gene_name_ortho.keys():
			ortho_status = 'Yes'
			ortho_set = chicken_ensembl_gene_id2human_ensembl_gene_name_ortho[ingeneid]
			orthologue = ';'.join(map(str,ortho_set))
		if ingeneid not in chicken_ensembl_gene_id2human_ensembl_gene_name_ortho.keys():
			ortho_status = 'No'
			orthologue = 'NA'
		# Annotate gene if found in cancer gene consensus
		if ingeneid in chicken_ensembl_gene_id2human_ensembl_gene_name_ortho.keys():
			for human_ensembl_gene_name in chicken_ensembl_gene_id2human_ensembl_gene_name_ortho[ingeneid]:
				if human_ensembl_gene_name in cgc_gene_set:
					cgc_status = 'Yes'
				elif human_ensembl_gene_name not in cgc_gene_set:
					cgc_status = 'No'
		# Annotate variant by consenus of variant callers (need to extract information from vep files)
		callers = []
		vep_samples = set(incol[9].split('|'))
		# If the variant is an snv
		if len(inref) == 1 and len(inalt) == 1:
			var_type = 'snv'
		elif len(inref) != 1 or len(inalt) != 1:
			var_type = 'indel'
		for vep_sample in vep_samples:
			vep_file = "./data/somaticseq_vcf/"+vep_sample+"_somaticseq_"+var_type+"_vep.vcf"
			for vep_line in open(vep_file):
				if vep_line[0] != '#':
					vep_line = vep_line.rstrip()
					vep_cols = vep_line.split('\t')
					vep_chr = vep_cols[0]
					vep_pos = vep_cols[1]
					vep_ref = vep_cols[3]
					vep_alt = vep_cols[4]
					vep_var = vep_chr+vep_pos+vep_ref+vep_alt
					vep_info = vep_cols[7]
					if vep_var == var_id:
						if re.search('NUM_TOOLS', vep_info.split(';')[1]):
							vep_tool_num = vep_info.split(';')[1][-1]
						elif re.search('NUM_TOOLS', vep_info.split(';')[2]):
							vep_tool_num = vep_info.split(';')[2][-1]
			callers.append(vep_tool_num)
			alg_num = ';'.join(map(str,callers))
		# Filter 1: Variants that occur in more than one tumor sample (filter out undesirable genes, e.g. olfactory receptors)
		if int(intsn_by_var) > 1 and ortho_status == 'Yes' and orthologue[0:2] != 'OR' and var_id not in final_var_set:
			filter_status = '1'
			final_var_set.add(var_id)
			outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
		# Filter 2: Variants in genes, which are mutated with different variants in multiple samples (filter out undesirable genes, e.g. olfactory receptors)
		if int(intsn_by_gene) > 1 and ortho_status == 'Yes' and orthologue[0:2] != 'OR' and var_id not in final_var_set:
			filter_status = '2'
			final_var_set.add(var_id)
			outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
		# Filter 3: Variants that are found in COSMIC's cancer gene consensus (filter out undesirable genes, e.g. olfactory receptors)
		if cgc_status == 'Yes' and ortho_status == 'Yes' and orthologue[0:2] != 'OR' and var_id not in final_var_set:
			filter_status = '3'
			final_var_set.add(var_id)
			outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
		# Filter 4: Variants with a consensus of gene callers greater than 1 and variant allele count greater than one
		for call_num in alg_num.split(';'):
			for vac in invac.split(';'):
				if int(call_num) > 1 and int(vac) > 1 and ortho_status == 'Yes' and orthologue[0:2] != 'OR' and var_id not in final_var_set:
					filter_status = '4'
					final_var_set.add(var_id)
					outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
		# Filter 5: Variants with a mutation that is associated with a high impact (annotaion via VEP) and variant allele count greater than 1
		if inimpact == 'HIGH' and int(vac) > 1 and ortho_status == 'Yes' and orthologue[0:2] != 'OR' and var_id not in final_var_set:
			filter_status = '5'
			final_var_set.add(var_id)
			outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
		# Filter 6: Variants with a consensus of gene callers greater than 1
		for call_num in alg_num.split(';'):
			for vac in invac.split(';'):
				if int(call_num) > 1 and ortho_status == 'Yes' and orthologue[0:2] != 'OR' and var_id not in final_var_set:
					filter_status = '6'
					final_var_set.add(var_id)
					outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
		# Filter 7: The remaining variants
		if var_id not in final_var_set:
			filter_status = '7'
			final_var_set.add(var_id)
			outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+inimpact+'\t'+insymbol+'\t'+ingeneid+'\t'+orthologue+'\t'+intsn_by_var+'\t'+intsn_by_gene+'\t'+insample+'\t'+invac+'\t'+invaf+'\t'+alg_num+'\t'+cgc_status+'\t'+filter_status+'\n')
# Close outfile
outfile.close
###################################

# Sort the output file by filter order to prioiritize varaints
sort -k17,17n ./data/somatic_snvs_and_indels_final_priority.int > \
./data/somatic_snvs_and_indels_final_priority.txt

# Grab the first 150 prioiritized variants
head -n151 ./data/somatic_snvs_and_indels_final_priority.txt > \
./data/somatic_snvs_and_indels_final_priority_n150.txt


# Extract 100 bp flanking sequences up- and down-stream from each somatic variant site

# seperate the galgal5 reference by chromosome
cd /home/proj/MDW_genomics/steepale/galgal5/
mkdir contig_fastas
cd contig_fastas
faidx --split-files /home/proj/MDW_genomics/steepale/galgal5/galgal5.fa
cdval

# Use bedtools to extract the 100 bp before and after a variant
# bedtools doc: http://bedtools.readthedocs.io/en/latest/content/tools/getfasta.html

# Take a final somatic variants file and format it to bed file
# Bed format is 0-based while VCF is 1-based

# Reference to Biopython (Bio.motifs): Please cite our application note [1, Cock et al., 2009] as the main Biopython reference. In addition, please cite any publications from the following list if appropriate, in particular as a reference for specific modules within Biopython (more information can be found on our website):
# http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc218
# Downloaded Biopython from http://biopython.org/wiki/Download version 1.69 on April 23, 2017

# Obtian th 100 bp flanking regions up- and down-stream from each somatic variant
python ./scripts/somatic_snvs_indels_flanking_regions.py \
./data/somatic_snvs_and_indels_final_priority_n150.txt \
./results/somatic_snvs_indels_flanking_100bp_top150.int


# ./scripts/somatic_snvs_indels_flanking_regions.py
#####################################
import sys
import os
from os import listdir
import subprocess
from subprocess import check_output
import re
import time
from difflib import SequenceMatcher
from Bio import motifs
from Bio.Seq import Seq
from pyfaidx import FastaVariant

# infile
infile = sys.argv[1]

# reference files
galgal5_fa = "/home/proj/MDW_genomics/steepale/galgal5/galgal5.fa"

# Add bam files to set
bams = set()
for bamfile in listdir("/home/proj/MDW_genomics/xu/final_bam"):
	if re.search("bam$", bamfile):
		bams.add("/home/proj/MDW_genomics/xu/final_bam/" + bamfile)

# outfiles
outfile = open(sys.argv[2], 'w')
delinquent_file = open("./data/delinquent_sequences_vars.txt" , 'w')

# Create a header for output file
outfile.write('#CHROM'+'\t'+'POS'+'\t'+'REF'+'\t'+'ALT'+'\t'+'VARIANT_TYPE'+'\t'+'SAMPLE'+'\t'+'DOWNSTREAM_POS'+'\t'+'UPSTREAM_POS'+'\t'+'IUPAC_CONSENSUS_SEQ_100BP_DOWNSTREAM'+'\t'+'SOMATIC_VARIANT'+'\t'+'IUPAC_CONSENSUS_SEQ_100BP_UPSTREAM'+'\t'+'SIMILARITY'+'\n')

# Function for sequence matching similarity
def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()

# Define sets
delinq_set = set()

# iterate through infile and capture variables
for inline in open(infile):
	if inline[0] != '#':
		inline = inline.rstrip()
		incol = inline.split('\t')
		inchr = incol[0]
		inpos = incol[1]
		inref = incol[2]
		inalt = incol[3]
		invar = inchr +'\t'+ inpos +'\t'+ inref +'\t'+ inalt
		insample = incol[11]
		# write the int variant file in basic bed format for a single variant position from reference sequence
		if len(inref) == 1 and len(inalt) == 1:
			inmut = 'SNV'
			start_var = int(inpos) - 1
			end_var = int(inpos)
			som_var = inalt
		elif len(inref) > 1:
			inmut = 'DEL'
			start_var = int(inpos) - 1
			end_var = int(inpos) + len(inref) - 1
			som_var = inref[0] + '-'*(len(inref) - 1)
		elif len(inalt) > 1:
			inmut = 'INS'
			start_var = int(inpos) - 1
			end_var = int(inpos) + len(inalt) - 1
			somvar = inref[0] + '+'*(len(inalt) -1)
		outfile_bed = "./data/somatic_var_bed.bed"
		outfile_bed = open(outfile_bed, 'w')
		outfile_bed.write(inchr + '\t' + str(start_var) + '\t' + str(end_var) + '\n')
		outfile_bed.close()
		# Use samtools mpileup to query the galgal5 reference file
		bedtools_var_cmd = "bedtools getfasta -fi "+galgal5_fa+" -bed ./data/somatic_var_bed.bed"
		# Use subprocess.Popen to ellicit shell commands 
		bedtools_var_proc = subprocess.Popen([bedtools_var_cmd], stdout=subprocess.PIPE, shell=True)
		# Use communicate to capture the output in a 'bytes' object
		(var_out, var_err) = bedtools_var_proc.communicate()
		# Decode the 'bytes' object to a string
		bedtools_var_out = var_out.decode("utf-8").rstrip().split('\n')[1]
		ref_var_out = bedtools_var_out
		#print('Variant' +' \t' + invar + '\t' + inmut)
		#print('ref_var_out ' + ref_var_out)

		# write the int downstream file in basic bed format for 100 bp downstream of single var position from reference sequence
		# For each upstream and downstream sequence:
		for flank in ['up', 'down']:
			if flank == 'up':
				start_flank_0 = int(inpos) + len(inref) - 1
				end_flank_0 = start_flank_0 + 100
				start_flank_1 = start_flank_0 + 1
				end_flank_1 = end_flank_0 + 1
				#elif inmut == 'DEL':
				#	start_flank_0 = int(inpos) + len(inref) - 1
				#	end_flank_0 = start_flank_0 + 100
				#	start_flank_1 = start_flank_0 + 1
				#	end_flank_1 = end_flank_0 + 1
			elif flank == 'down':
				start_flank_0 = start_var - 100
				end_flank_0 = start_var
				start_flank_1 = start_var - 100
				end_flank_1 = start_var

			outfile_flank = "./data/somatic_var_flank.bed"
			outfile_flank = open(outfile_flank, 'w')
			outfile_flank.write(inchr + '\t' + str(start_flank_0) + '\t' + str(end_flank_0) + '\n')
			outfile_flank.close()
			bedtools_flank_cmd = "bedtools getfasta -fi "+galgal5_fa+" -bed ./data/somatic_var_flank.bed"
			# Use subprocess.Popen to ellicit shell commands 
			bedtools_flank_proc = subprocess.Popen([bedtools_flank_cmd], stdout=subprocess.PIPE, shell=True)
			# Use communicate to capture the output in a 'bytes' object
			(flank_out, flank_err) = bedtools_flank_proc.communicate()
			# Decode the 'bytes' object to a string
			ref_flank_out = flank_out.decode("utf-8").rstrip().split('\n')[1]
			#print('Variant' +' \t' + invar + '\t' + inmut + '\t' + insample)
			#print('Flank: ' + flank)
			#print('start_flank_1: ' + str(start_flank_1))
			#print('end_flank_1: ' + str(end_flank_1))
			#print('ref_flank_out' +'\t'+ ref_flank_out)
			#print(len(ref_flank_out))
			#print(str(start_flank_1) + '-' + str(end_flank_1)) 
			# Create empty sequence list
			bamseqList = []
			# Iterate over bam files to collect downstream primer sequence for each sample
			for bamfile in bams:
					#print(bamfile)
					# Create a samtools command to create a intermediate bam file of region of interest
					samtools_view_cmd = "samtools view -ub "+bamfile+" "+inchr+":"+str(start_flank_1)+"-"+str(end_flank_1)+" > ./data/int_flank.bam"
					os.system(samtools_view_cmd)
					samtools_index_cmd = "samtools index ./data/int_flank.bam"
					os.system(samtools_index_cmd)
					#time.sleep(1)
					# Samtools and mpileup work together to call variants at region of interest
					samtools_mpileup_flank_cmd = "samtools mpileup -uf "+galgal5_fa+" ./data/int_flank.bam -d 5000 | bcftools call -c -Oz -o ./data/int_flank.vcf.gz"
					os.system(samtools_mpileup_flank_cmd)
					#time.sleep(1)
					tabix_flank_cmd = "tabix -f -p vcf ./data/int_flank.vcf.gz"
					os.system(tabix_flank_cmd)
					filter_cmd = "bcftools filter -O z -o ./data/int_flank_filter.vcf.gz -s LOWQUAL -i'%QUAL>10' ./data/int_flank.vcf.gz"
					os.system(filter_cmd)
					tabix_filter_cmd = "tabix -f -p vcf ./data/int_flank_filter.vcf.gz"
					os.system(tabix_filter_cmd)
					#time.sleep(1)

					# Determine the consensus sequence of the region of interest using ref chr and vcf file
					with FastaVariant("/home/proj/MDW_genomics/steepale/galgal5/contig_fastas/"+inchr+".fa", './data/int_flank_filter.vcf.gz', het=True, hom=True) as consensus:
						for chromosome in consensus:
							if flank == 'down':
								site = int(end_flank_1)
							elif flank == 'up':
								site = int(end_flank_1 - 1)
							bam_flank_100 = chromosome[site-100:site]
							final_flank_out = bam_flank_100.seq
							# Add sequences to a list
							bamseqList.append(final_flank_out)

							# Check for the accuracy of each sample's 100bp sequence with that of the reference sequence
							similarity = similar(ref_flank_out, final_flank_out)
						if similarity < 1  and flank == 'down' and invar not in delinq_set:
							delinq_set.add(invar)
							delinquent_file.write('\n' + invar + '\n')
							delinquent_file.write('Downstream Reference Sequence:' + '\n' + ref_flank_out + '\n')
							delinquent_file.write(bamfile + ' SIMILARITY: ' + str(similarity) + '\n' + final_flank_out + '\n')
						elif similarity < 1 and flank == 'down' and invar in delinq_set:
							delinquent_file.write(bamfile + ' SIMILARITY: ' + str(similarity) + '\n' + final_flank_out + '\n')
						if similarity < 1  and flank == 'up' and invar not in delinq_set:
							delinq_set.add(invar)
							delinquent_file.write('\n' + invar + '\n')
							delinquent_file.write('Upstream Reference Sequence:' + '\n' + ref_flank_out + '\n')
							delinquent_file.write(bamfile + ' SIMILARITY: ' + str(similarity) + '\n' + final_flank_out + '\n')
						elif similarity < 1 and flank == 'up' and invar in delinq_set:
							delinquent_file.write(bamfile + ' SIMILARITY: ' + str(similarity) + '\n' + final_flank_out + '\n')

			# List of all downstreamm flanking sequences for 1 sample = bamseqList
			# load the motifs into an array-like object in biopython
			m = motifs.create(bamseqList)
			# create a IUPAC consensus sequence
			consensus_flank_IUPAC = m.degenerate_consensus
			# create a consensus sequence of the most frequent nucleotide per loci (no ambigous letters)
			consensus_flank = m.consensus
			if flank == 'up':
				consensus_upstream = str(consensus_flank)
				similarity_up = similar(ref_flank_out, consensus_upstream)
				upstream_pos = inchr+':'+str(start_flank_1)+'-'+str(end_flank_1 - 1)
			elif flank == 'down':
				consensus_downstream = str(consensus_flank)
				similarity_down = similar(ref_flank_out, consensus_downstream)
				downstream_pos = inchr+':'+str(start_flank_1 + 1)+'-'+str(end_flank_1)
			#print(m.counts)
			#print('Consensus: ' + '\n' + consensus_flank)
			#print('IUPAC: ' +'\n' + consensus_flank_IUPAC)
		outfile.write(inchr+'\t'+inpos+'\t'+inref+'\t'+inalt+'\t'+inmut+'\t'+insample+'\t'+downstream_pos+'\t'+upstream_pos+'\t'+consensus_downstream+'\t'+som_var+'\t'+consensus_upstream+'\t'+str(similarity_down)+';'+str(similarity_up)+'\n')

outfile.close()
########################	

# Sloppy script run to get the downstream and upstream sequences for 50 bp regions
python ./scripts/somatic_snvs_indels_flanking_regions.py ./data/somatic_snvs_and_indels_final_priority_50bp.txt \
./results/somatic_snvs_indels_flanking_100bp_top50bp.int
		
# Grant priority column to ./results/somatic_snvs_indels_flanking_100bp_top150
python ./scripts/grant_priority_sites_w_flanks.py \
./results/somatic_snvs_and_indels_final_priority_n150_w_priority.txt \
./results/somatic_snvs_and_indels_final_priority_n150_no_priority.txt \
./results/somatic_snvs_and_indels_top_156.txt

# ./scripts/grant_priority_sites_w_flanks.py
############################
import sys
import os

# infiles
p_file = sys.argv[1]
no_p_file= sys.argv[2]

# outfile
outfile = open(sys.argv[3], 'w')

# Create empty dictionary
var2prior = {}

# iterate through infile with priority and create dictionary of variants and their corresponding priority
for p_line in open(p_file):
	if p_line[0] != '#':
		p_line = p_line.rstrip()
		p_col = p_line.split('\t')
		p_var = p_col[0] + p_col[1] + p_col[2] + p_col[3]
		p_priority = p_col[18]
		var2prior[p_var] = p_priority

# iterate through the file with no priority and add the priority to the last column
for no_p_line in open(no_p_file):
	# Write the header for the outfile
	no_p_line = no_p_line.rstrip()
	if no_p_line[0] == '#':
		outfile.write(no_p_line + '\t' + 'PRIORITY' + '\n')
	if no_p_line[0] != '#':
		no_p_col = no_p_line.split('\t')
		CHROM = no_p_col[0]
		POS = no_p_col[1]
		REF = no_p_col[2]
		ALT = no_p_col[3]
		no_p_var = no_p_col[0] + no_p_col[1] + no_p_col[2] + no_p_col[3]
		VARIANT_TYPE = no_p_col[4]
		SAMPLE = no_p_col[5]
		DOWNSTREAM_POS= no_p_col[6]
		UPSTREAM_POS = no_p_col[7]
		IUPAC_CONSENSUS_SEQ_100BP_DOWNSTREAM = no_p_col[8]
		SOMATIC_VARIANT = no_p_col[9]
		IUPAC_CONSENSUS_SEQ_100BP_UPSTREAM = no_p_col[10]
		SIMILARITY = no_p_line[11]
		if no_p_var in var2prior.keys():
			PRIORITY = str(var2prior[no_p_var])
			#Write the outfile
			outfile.write(no_p_line + '\t' + PRIORITY + '\n')
outfile.close()
############################

# Final files after custom manipulation in excel:
./results/somatic_snvs_and_indels_top_156.txt
./results/somatic_snvs_and_indels_final_priority_n150.txt









		








